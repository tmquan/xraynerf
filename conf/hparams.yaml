hydra:
  output_subdir: null
  run:
    dir: .


defaults:
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled


data:
  data_dir: "/home/quantm/data"
  train_samples: 2000
  val_samples: 1
  test_samples: 1
  train_image3d_folders:
    - "/home/quantm/data/ChestXRLungSegmentation/NSCLC/processed/train/images"
    - "/home/quantm/data/ChestXRLungSegmentation/MOSMED/processed/train/images/CT-0"
    - "/home/quantm/data/ChestXRLungSegmentation/MOSMED/processed/train/images/CT-1"
    - "/home/quantm/data/ChestXRLungSegmentation/MOSMED/processed/train/images/CT-2"
    - "/home/quantm/data/ChestXRLungSegmentation/MOSMED/processed/train/images/CT-3"
    - "/home/quantm/data/ChestXRLungSegmentation/MOSMED/processed/train/images/CT-4"
    - "/home/quantm/data/ChestXRLungSegmentation/Imagenglab/processed/train/images"
  train_label3d_folders: []
  train_image2d_folders:
    - "/home/quantm/data/ChestXRLungSegmentation/VinDr/v1/processed/train/images/"
  train_label2d_folders: []
  val_image3d_folders:
    - "/home/quantm/data/ChestXRLungSegmentation/NSCLC/processed/train/images"
    - "/home/quantm/data/ChestXRLungSegmentation/MOSMED/processed/train/images/CT-0"
    - "/home/quantm/data/ChestXRLungSegmentation/MOSMED/processed/train/images/CT-1"
    - "/home/quantm/data/ChestXRLungSegmentation/MOSMED/processed/train/images/CT-2"
    - "/home/quantm/data/ChestXRLungSegmentation/MOSMED/processed/train/images/CT-3"
    - "/home/quantm/data/ChestXRLungSegmentation/MOSMED/processed/train/images/CT-4"
    - "/home/quantm/data/ChestXRLungSegmentation/Imagenglab/processed/train/images"
  val_label3d_folders: []
  val_image2d_folders:
    - "/home/quantm/data/ChestXRLungSegmentation/VinDr/v1/processed/test/images/"
  val_label2d_folders: []
  test_image3d_folders:
    - "/home/quantm/data/ChestXRLungSegmentation/NSCLC/processed/train/images"
    - "/home/quantm/data/ChestXRLungSegmentation/MOSMED/processed/train/images/CT-0"
    - "/home/quantm/data/ChestXRLungSegmentation/MOSMED/processed/train/images/CT-1"
    - "/home/quantm/data/ChestXRLungSegmentation/MOSMED/processed/train/images/CT-2"
    - "/home/quantm/data/ChestXRLungSegmentation/MOSMED/processed/train/images/CT-3"
    - "/home/quantm/data/ChestXRLungSegmentation/MOSMED/processed/train/images/CT-4"
    - "/home/quantm/data/ChestXRLungSegmentation/Imagenglab/processed/train/images"
  test_label3d_folders: []
  test_image2d_folders:
    - "/home/quantm/data/ChestXRLungSegmentation/VinDr/v1/processed/test/images/"
  test_label2d_folders: []
  img_shape: 256
  vol_shape: 256
  batch_size: 1


model:  
  phase: "voxelgrid" #"pixelnerf" "ctproj" #"ctxray"
  img_shape: ${data.img_shape}
  vol_shape: ${data.vol_shape}
  fov_depth: 256
  batch_size: ${data.batch_size}
  n_pts_per_ray: 256
  unetmodel:
    _target_: generative.networks.nets.DiffusionModelUNet
    spatial_dims: 2
    in_channels: 1
    out_channels: 1
    num_channels: [256, 256, 512]
    attention_levels: [false, false, true]
    num_head_channels: [0, 0, 512]
    num_res_blocks: 2
    with_conditioning: true
    cross_attention_dim: 16
    upcast_attention: true
    use_flash_attention: true
    dropout_cattn: 0.5
  scheduler:
    _target_: generative.networks.schedulers.DDIMScheduler
    num_train_timesteps: 1000
    schedule: "linear_beta"
    clip_sample: true
    set_alpha_to_one: true
    steps_offset: 0
    prediction_type: sample # epsilon 
  inferer:
    _target_: generative.inferers.DiffusionInferer
    scheduler: ${model.scheduler}
    # num_inference_timesteps: 1000use the following
  

train:
  ckpt: ${resume_from_checkpoint}
  strict: 1 if ${resume_from_checkpoint} is not None else 0
  lr: 1e-4
  alpha: 1
  gamma: 1
  batch_size: ${data.batch_size}
  epochs: 200
  ema_decay: 0.9999 # `-1` disables it


infer:
  num_samples: 8 # or 50,000

# resume_from_checkpoint: "logs/ctproj/version_0/checkpoints/epoch=159-step=320000.ckpt" #null
resume_from_checkpoint: null

trainer:
  accelerator: auto
  devices: -1
  precision: 32
  strategy: auto
  max_epochs: ${train.epochs}
  enable_model_summary: true

callbacks:
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    monitor: "validation_loss_epoch"
    auto_insert_metric_name: true
    save_top_k: -1
    save_last: true
    every_n_epochs: 10
  - _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: 'epoch'
    log_momentum: true
    log_weight_decay: true
  - _target_: lightning.pytorch.callbacks.RichProgressBar
    refresh_rate: 1
  - _target_: lightning.pytorch.callbacks.StochasticWeightAveraging
    swa_lrs: 1e-3  

logger:
  - _target_: lightning.pytorch.loggers.TensorBoardLogger
    save_dir: "./logs"
    log_graph: true
    name: ${model.phase}


# scheduler:
#   clip_sample: true
# pipeline_kwargs:
#   batch_size: 256
#   num_inference_steps: 1000

# defaults:
#   - models@models.unet: diffusers_native #better_cifar10 # diffusers_native
#   - data: gray
#   - scheds@training.scheduler: ddpm
#   - scheds@inference.scheduler: ddpm
#   - logger: tb
#   - _self_
#   - override hydra/hydra_logging: disabled
#   - override hydra/job_logging: disabled

# training:
#   batch_size: 128
#   lr: 1.e-4
#   epochs: 300
#   ema_decay: 0.9999 # `-1` disables it


# inference:
#   num_samples: 1024 # or 50,000
#   scheduler:
#     clip_sample: true
#   pipeline_kwargs:
#     batch_size: 256
#     num_inference_steps: 1000